{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"TasCreed","text":"<p>Welcome to TasCreed! Execute task with creed!</p> <p>TasCreed is a light-weighted framework for reliable distributed task execution.</p>"},{"location":"index.html#why-tascreed","title":"Why TasCreed","text":"<p>When we execute a task, it is usually expected to be accomplished unwaveringly, without any maintenance effort.</p> <p>TasCreed is designed to provide such commitment.</p> <ul> <li>task execution can recover from environment issue, such as node crash</li> <li>submitted job will be executed thoroughly, eventually</li> </ul> <p>Besides the basic goals, TasCreed also provides more convenience for users to execute tasks in a distributed way.</p> <ul> <li>execute tens of tasks in parallel, with simple configuration</li> <li>split a batch of data into partitions, and execute them in parallel</li> <li>create long run job to execute mini-batches continuously</li> </ul> <p>These features are really useful in some special scenarios.</p> <p>Tips</p> <p>Please be aware that, a task is executed at least once, so the side effect of the task should be idempotent. This is also a common requirement for the retryable batch jobs.</p>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<p>You can have a quick try of the TasCreed framework with a sample application.</p>"},{"location":"index.html#tutorial","title":"Tutorial","text":"<p>You can refer to more documents to learn the details about TasCreed.</p> <ul> <li>Design: concepts and architecture </li> <li>Detail: more details of features and usage</li> <li>Spec: spec explanation of domain objects</li> <li>Config: configuration properties</li> <li>Misc: notes of released and planned features, as well as the tips for upgrade</li> </ul>"},{"location":"Quickstart.html","title":"Quick Start","text":"<p>TBD</p> <p>In TasCreed, the general usage falls into two phases: preparation and run.</p> <p>You can have a try of the sample application.</p>"},{"location":"Quickstart.html#sample-application","title":"Sample application","text":""},{"location":"Quickstart.html#preparation","title":"Preparation","text":""},{"location":"Quickstart.html#compilation","title":"Compilation","text":""},{"location":"Quickstart.html#configuration","title":"Configuration","text":""},{"location":"Quickstart.html#define-job","title":"Define job","text":""},{"location":"Quickstart.html#run","title":"Run","text":""},{"location":"Quickstart.html#trigger-job","title":"Trigger job","text":""},{"location":"Quickstart.html#check-job-status","title":"Check job status","text":""},{"location":"Quickstart.html#examine-job-result","title":"Examine job result","text":""},{"location":"config/InfraConfig.html","title":"Infra Config","text":"<p>By default, TasCreed infra config is stored in <code>tascreed.yaml</code>, which can be partially overwritten by application properties file.</p> <p>This document introduces the properties.</p>"},{"location":"config/InfraConfig.html#basic","title":"Basic","text":"Param Name Description Type Overwrite Default Value <code>tascreed.namespace</code> namespace of your TasCreed application, should be unique <code>string</code> MUST <code>/tascreed/default</code> <code>tascreed.define.dirs</code> job define file directories, split by <code>,</code>, <code>*.json</code> files are loaded <code>string</code> OPTIONAL <code>jobDefine</code> <code>tascreed.define.graph.validate.enable</code> if enabled, will validate cyclic dependency of defined steps <code>bool</code> OPTIONAL <code>true</code>"},{"location":"config/InfraConfig.html#task-worker","title":"Task worker","text":"Param Name Description Type Overwrite Default Value <code>tascreed.watcher.task.switch.on.default</code> if disabled, will not pick any task <code>bool</code> OPTIONAL <code>true</code> <code>tascreed.watcher.task.interval.seconds</code> the interval of task watcher thread loop, to pick tasks <code>int</code> OPTIONAL <code>30</code> <code>tascreed.worker.max.count.overall.default</code> the default number of task worker threads across all nodes <code>int</code> RECOMMEND <code>20</code> <code>tascreed.worker.max.count.per.host.default</code> the default number of task worker threads on each node <code>int</code> RECOMMEND <code>5</code> <code>tascreed.worker.affinity.enable</code> if enabled, will consider affinity rules when assigning tasks <code>bool</code> OPTIONAL <code>false</code>"},{"location":"config/InfraConfig.html#routine-worker","title":"Routine worker","text":"Param Name Description Type Overwrite Default Value <code>tascreed.watcher.routine.switch.on.default</code> if disabled, will not pick any routine <code>bool</code> OPTIONAL <code>true</code> <code>tascreed.watcher.routine.interval.seconds</code> the interval of routine watcher thread loop, to pick routines <code>int</code> OPTIONAL <code>30</code> <code>tascreed.routine.max.count.overall.default</code> the default number of routine worker threads across all nodes <code>int</code> RECOMMEND <code>20</code> <code>tascreed.routine.max.count.per.host.default</code> the default number of routine worker threads on each node <code>int</code> RECOMMEND <code>5</code>"},{"location":"config/InfraConfig.html#features","title":"Features","text":"Param Name Description Type Overwrite Default Value <code>tascreed.ban.enable</code> enable the feature to pause the job execution <code>bool</code> OPTIONAL <code>true</code> <code>tascreed.duty.enable</code> enable the feature of node duty rules <code>bool</code> OPTIONAL <code>true</code> <code>tascreed.archive.task.enable</code> enable the feature to archive finished tasks <code>bool</code> OPTIONAL <code>false</code>"},{"location":"config/InfraConfig.html#environment","title":"Environment","text":"Param Name Description Type Overwrite Default Value <code>tascreed.storage.bulletin</code> bulletin storage, could be <code>ETCD</code> <code>enum</code> OPTIONAL <code>ETCD</code> <code>tascreed.storage.archive</code> archive storages, split by <code>,</code>, could be <code>ES</code>, <code>ETCD</code>, <code>NONE</code> <code>enum</code> OPTIONAL <code>ES</code> <code>tascreed.logger</code> logger implementation <code>string</code> OPTIONAL <code>std</code> <code>tascreed.etcd</code> etcd implementation <code>string</code> OPTIONAL <code>mem</code> <code>tascreed.es</code> es implementation <code>string</code> OPTIONAL <code>disk</code> <code>tascreed.metrics.server.enable</code> enable prometheus metrics server <code>bool</code> OPTIONAL <code>true</code> <code>tascreed.metrics.server.port</code> prometheus metrics server port <code>int</code> OPTIONAL <code>9091</code> <p>Environment properties</p> <p>The default implementation of storages are simply in memory or disk, which is convenient for local test or debug.  Users can have their own implementations, and configure to switch the environment.</p>"},{"location":"design/Architecture.html","title":"Architecture","text":"<pre><code>flowchart LR\n    subgraph node[App Node]\n        server[Job Server]\n        worker[Task Worker]\n    end\n\n    user(User)\n    bulletin[Bulletin]\n    archive[Archive]\n\n    user --&gt;|\"submit job request\"| server\n\n    server --&gt;|\"create job\"| bulletin\n    server --&gt;|\"proceed job\"| bulletin\n    server --&gt;|\"archive job\"| archive\n\n    worker --&gt;|\"occupy task\"| bulletin\n    worker --&gt;|\"execute task\"| worker\n    worker --&gt;|\"update task\"| bulletin</code></pre>"},{"location":"design/Architecture.html#component","title":"Component","text":""},{"location":"design/Architecture.html#job-server","title":"Job Server","text":"<p>Job server manages the lifecycle of jobs and tasks. </p> Action When How create job user submits job request find job define, create a new job instance proceed job periodically fetch job and done tasks, update job status, create subsequent tasks archive job periodically fetch done jobs and tasks, archive them"},{"location":"design/Architecture.html#task-worker","title":"Task Worker","text":"<p>Task worker executes tasks, and updates task status.</p> Action When How occupy task periodically fetch todo tasks, occupy a task; keep heartbeat of occupation execute task task adopted execute task internally update task task done update task status Why not assign task to worker? <p>In some other task execution framework, a leader role (similar to \"job server\") will assign a task to specific worker. By managing the aliveness of all workers, the leader can assign tasks flexibly, such as considering resource capacity, network affinity. However, the leader role also introduces more complexity of design and implementation.</p> <p>To simplify the system, TasCreed adopts a leaderless design, each node has the same functionality, works independently. Each worker occupies tasks by itself, which makes it easy to implement, deploy, and scale.</p>"},{"location":"design/Architecture.html#storage","title":"Storage","text":"<p>There are two kinds of storages, bulletin and archive.</p> <ul> <li>Bulletin stores the status of alive jobs and tasks, as well as the task occupations.</li> <li>Archive stores the records of done jobs and tasks.</li> </ul> What kind of storage can work as bulletin? <p>Most storages can easily store the status of alive jobs and tasks, but for task occupation, the solutions would be different.</p> <ul> <li>In traditional databses, task occupation can be stored in a dedicated table, then orphan record would exist if worker crashes.</li> <li>A timeout mechanism helps, the worker keeps refresh the aliveness of the occupation, then orphan record can be cleaned or easily recognized if worker crashes.  </li> </ul> <p>Therefore, the bulletin can be implemented by lots of storages. We've chosen etcd by default, for its native feature of lease.</p> What kind of storage can work as archive? <p>Most storages can support the archive requirement, thus there could be lots of options.</p>"},{"location":"design/Architecture.html#workflow","title":"Workflow","text":""},{"location":"design/Architecture.html#job-trigger","title":"Job Trigger","text":"<pre><code>flowchart LR\n    user(User) --&gt;|\"1. submit job request\"| server[Job Server]\n    server --&gt;|\"2. create new job\"| server\n    server --&gt;|\"3. write new job\"| bulletin[Bulletin]</code></pre> <ol> <li>User submit a job request</li> <li>Job server validate the request, find the job define, and create a new job</li> <li>Job server write the new job to bulletin<ul> <li>If the job is a duplicate one, it will be rejected</li> <li>A job is non-duplicate only if it can not be found in both bulletin and archive</li> </ul> </li> </ol>"},{"location":"design/Architecture.html#task-execution","title":"Task Execution","text":"<pre><code>flowchart LR\n    worker[Task Worker] -.-&gt;|\"1. fetch todo tasks and occupations\"| bulletin[Bulletin]\n    worker --&gt;|\"2. occupy a task and keep heartbeat\"| bulletin\n    worker --&gt;|\"3. execute task\"| worker\n    worker --&gt;|\"4. update task status\"| bulletin</code></pre> <ol> <li>Worker fetch todo tasks and current occupations from bulletin</li> <li>Worker pick a valid todo task, occupy it in bulletin, periodically heartbeat to keep the occupation</li> <li>Worker execute the task</li> <li>After execution, worker update the task status to done, and remove the occupation</li> </ol>"},{"location":"design/Architecture.html#job-update","title":"Job Update","text":"<pre><code>flowchart LR\n    server[Job Server] -.-&gt;|\"1. fetch alive jobs and done tasks\"| bulletin[Bulletin]\n    server --&gt;|\"2. update job status, create new todo tasks\"| bulletin</code></pre> <ol> <li>Server fetch alive jobs and done tasks from bulletin</li> <li>Server update the job status by done tasks, and create more executable tasks</li> </ol>"},{"location":"design/Architecture.html#thread-model","title":"Thread model","text":"<p>In each TasCreed node, there are some threads to handle the job and task lifecycle.</p> Thread Description job server when receive a job request, create new job job watcher periodically update job status, create new tasks task watcher periodically occupy task, build worker thread task worker execute task, with a companion heartbeat thread to keep occupation <p>Note</p> <p>The thread model just illustrates the design principle, not the exact implementation. For example, the job watcher is implemented as a routine worker across the whole cluster.</p>"},{"location":"design/Concept.html","title":"Concept","text":"<pre><code>erDiagram\n    JobDefine {\n        string jobName\n        StepDefine[] steps\n    }\n\n    StepDefine {\n        string stepName\n        string[] dependentSteps\n    }\n\n    JobRequest {\n        string jobName\n        string trigger\n    }\n\n    Job {\n        string jobName\n        string trigger\n        StepDefine[] steps\n    }\n\n    Step {\n        string stepName\n    }\n\n    Task {\n        string jobName\n        string trigger\n        string stepName\n    }\n\n    JobDefine ||--o{ StepDefine : has\n    Job ||--o{ Step : has\n\n    JobRequest ||--|| Job : triggers\n    JobDefine ||--o{ Job : instantiates\n    StepDefine ||--o{ Step : instantiates\n\n    Step ||--|{ Task : generates</code></pre> <ul> <li><code>JobDefine</code>: definition of job, containing <code>StepDefine</code>s</li> <li><code>StepDefine</code>: definition of step, with dependency of other steps</li> <li><code>JobRequest</code>: request to trigger a <code>Job</code></li> <li><code>Job</code>: instance of a <code>JobDefine</code>, triggered by a <code>JobRequest</code></li> <li><code>Step</code>: instance of a <code>StepDefine</code>, contained by a <code>Job</code></li> <li><code>Task</code>: execution unit of a <code>Step</code></li> </ul>"},{"location":"design/Concept.html#job-define","title":"Job Define","text":"<p><code>JobDefine</code> is pre-defined as job template, identified by <code>jobName</code>. e.g.</p> <pre><code>{\n  \"jobName\": \"balance-report\",\n  \"steps\": [...]\n}\n</code></pre>"},{"location":"design/Concept.html#step-define","title":"Step Define","text":"<p><code>StepDefine</code> is pre-defined as step template, identified by <code>stepName</code> within its belonged <code>JobDefine</code>. e.g.</p> <pre><code>{\n  \"stepName\": \"merge_sharding_files_and_upload\",\n  \"sharding\": 12,\n  \"dependentStep\": \"generate_files_and_upload_by_sharding\"\n}\n</code></pre>"},{"location":"design/Concept.html#job-request","title":"Job Request","text":"<p><code>JobRequest</code> is submitted by user, to create a new job instance. e.g.</p> <pre><code>{\n  \"jobName\": \"balance-report\",\n  \"trigger\": \"20191031\",\n  \"steps\": [\n    \"stepName\": \"balance-report-calculate\",\n    \"params\": {\n      \"param1\": \"value1\",\n      \"param2\": \"value2\"\n    }\n  ]\n}\n</code></pre>"},{"location":"design/Concept.html#job","title":"Job","text":"<p><code>Job</code> is created based on the <code>JobDefine</code>, triggered by <code>JobRequest</code>, identified by <code>jobName</code> and <code>trigger</code>. e.g.</p> <pre><code>{\n  \"jobName\": \"balance-report\",\n  \"trigger\": \"20191113\", \n  \"steps\": [...],\n  \"state\": \"SUCCESS\"\n}\n</code></pre>"},{"location":"design/Concept.html#step","title":"Step","text":"<p><code>Step</code> is created based on the <code>StepDefine</code>, identified by <code>stepName</code> within its belonged <code>Job</code>. e.g.</p> <pre><code>{\n  \"name\": \"balance-report-calculate\",\n  \"state\": \"SUCCESS\",\n  \"taskStates\": {\n    \"3\": \"SUCCESS\",\n    \"4\": \"SUCCESS\",\n    \"2\": \"SUCCESS\",\n    \"1\": \"SUCCESS\"\n  },\n  \"params\": {\n    \"REQUEST\": \"...\"\n  }\n}\n</code></pre>"},{"location":"design/Concept.html#task","title":"Task","text":"<p><code>Task</code> is created based on the <code>Step</code>, globally identified by <code>jobName</code>, <code>trigger</code>, <code>stepName</code> and its partitioned information if any. e.g.</p> <pre><code>{\n  \"jobName\": \"balance-report\",\n  \"trigger\": \"20200121200001\",\n  \"stepName\": \"balance-report-calculate\",\n  \"sharding\": {\n    \"total\": 12,\n    \"index\": 9\n  },\n  \"params\": {\n    \"REQUEST\": \"{\\\"triggerId\\\":\\\"20200121200001\\\",\\\"reportDate\\\":\\\"2020-01-21\\\"}\",\n    \"host\": \"9\"\n  },\n  \"createTime\": \"2020-01-23T04:14:44.900Z\"\n}\n</code></pre>"},{"location":"detail/definition/Annotation.html","title":"Annotation","text":"<p>Users need to implement their own task executors, and register them to the framework.  Annotation helps to register the executors more efficiently.</p>"},{"location":"detail/definition/Annotation.html#without-annotation","title":"Without annotation","text":"<p>Task executors can be registered explicitly in code like this: <pre><code>taskExecutorRegistry.registerTaskExecutor(\"job1\", \"step1\", MyTaskExecutor.class);\n</code></pre></p> <p>It should be registered at the initialization phase of the application, then the framework can find the executor for the specific step.</p> <p>This way is more likely to be ignored by users, leading to unexpected exceptions.</p>"},{"location":"detail/definition/Annotation.html#with-annotation","title":"With annotation","text":"<p>Then we've introduced the annotation way to register task executors. For example,</p> <pre><code>@TaskExec(job=\"job1\", step=\"step1\")\n@TaskExec(job=\"job2\", step={\"step2\", \"step3\"})\n@Component\n@Scope(\"prototype\")\npublic class MyTaskExecutor extends NormalTaskExecutor {\n    ...\n}\n</code></pre> <ul> <li><code>job</code>: job name</li> <li><code>step</code>: list of step names</li> </ul> <p>The annotation describes which steps the task executor is bound to, during startup, the framework will register these executors automatically.</p> <p>This way is much more convenient and less error-prone.</p> <p><code>@Component</code> and <code>@Scope(\"prototype\")</code> are both necessary for task executors, because the executors are scanned by spring boot.</p>"},{"location":"detail/definition/Annotation.html#routine-executor","title":"Routine executor","text":"<p>Similarly, the routine executor can also be registered by annotation. For example,</p> <pre><code>@RoutineExec(routine=\"job-watcher\", scale = 3, priority = 100, interval = 30 * 1000L)\n@Component\n@Scope(\"prototype\")\npublic class JobWatcherRoutineExecutor extends NormalRoutineExecutor {\n    ...\n}\n</code></pre> <ul> <li><code>routine</code>: routine name</li> <li><code>scale</code>: the number of threads to run the routine, for high availability</li> <li><code>priority</code>: priority of the routine</li> <li><code>interval</code>: interval of the routine execution round</li> </ul>"},{"location":"detail/definition/Phase.html","title":"Phase","text":"<p>The step dependency describes the relationship between steps, and the results of previous step will affect the execution of the subsequent ones.</p> <p>For example, if a step finishes with a <code>FAILED</code> state, the following steps will be simply skipped with a <code>SKIP_BY_FAILED</code> state.  But sometimes, users might need a step that must be executed at last, just like the <code>finally</code> block does in Java application.</p> <p>The feature of phase definition is introduced to solve the problem, it can do even more than a <code>finally</code> step.</p>"},{"location":"detail/definition/Phase.html#phase-definition","title":"Phase definition","text":"<p>Each step can define its belonged phase, which is described as an integer number, by default <code>0</code>.</p> <p>The rule is simple, a phase can start, only if all its previous phases are done. The smaller phase number the higher priority.</p> <p>The step dependency describes a strong relationship, while the phase describes a weak dependency relationship. </p> <ul> <li>The step dependency restricts the step to check the results of its dependent steps are success or not;</li> <li>The phase dependency only restricts the step to check its dependent phase steps are done or not.</li> </ul> <p>Therefore, the results of steps in the dependent phase will not impact the execution of the steps in the next phase. </p> <p>For example, the <code>finally</code> step can be set with a larger phase number than other steps.</p>"},{"location":"detail/definition/Phase.html#example","title":"Example","text":"<p>Let's define steps like this:</p> <pre><code>flowchart TD\n    subgraph P0[\"Phase 0\"]\n        A --&gt; B\n        A --&gt; C\n        B --&gt; D\n        C --&gt; D\n        C --&gt; E\n    end\n    subgraph P1[\"Phase 1\"]\n        F --&gt; H\n        F --&gt; I\n        G --&gt; I\n    end\n    E --&gt; G\n    P0 -.-&gt; P1</code></pre> <p>The job define of the DAG as illustrated could be like this:</p> <pre><code>{\n  \"jobName\": \"dag\",\n  \"steps\": [\n    {\n      \"stepName\": \"A\"\n    },\n    {\n      \"stepName\": \"B\",\n      \"dependency\": {\n        \"steps\": [\"A\"]\n      }\n    },\n    {\n      \"stepName\": \"C\",\n      \"dependency\": {\n        \"steps\": [\"A\"]\n      }\n    },\n    {\n      \"stepName\": \"D\",\n      \"dependency\": {\n        \"steps\": [\"B\", \"C\"]\n      }\n    },\n    {\n      \"stepName\": \"E\",\n      \"dependency\": {\n        \"steps\": [\"C\"]\n      }\n    },\n    {\n      \"stepName\": \"F\",\n      \"dependency\": {\n        \"phase\": 1\n      }\n    },\n    {\n      \"stepName\": \"G\",\n      \"dependency\": {\n        \"phase\": 1,\n        \"steps\": [\"E\"]\n      }\n    },\n    {\n      \"stepName\": \"H\",\n      \"dependency\": {\n        \"phase\": 1,\n        \"steps\": [\"F\"]\n      }\n    },\n    {\n      \"stepName\": \"I\",\n      \"dependency\": {\n        \"phase\": 1,\n        \"steps\": [\"F\", \"G\"]\n      }\n    }\n  ]\n}\n</code></pre> <ul> <li>phase 0 is the first phase, phase 1 depends on phase 0.</li> <li>if <code>phase</code> not set, it is in phase 0 by default.</li> <li>the explicit dependency can across different phases, like step <code>G</code> in phase 1 explicitly depends on step <code>E</code> in phase 0. Step <code>G</code> starts after <code>E</code> is done, and the result state of <code>E</code> will impact <code>G</code> as well. That is the main difference between the step dependency and phase dependency.</li> <li>the steps in phase 1 will start only after all the steps in phase 0 are done.</li> <li>the phase number is unnecessary to be continuous, but it should not be negative number. For example, in a job define, we can only have phase 3 and 5, without configuring phase 0, 1, 2, 4. The execution order is from small phase to large one, that's all.</li> </ul> What if the phase dependency conflicts with the step dependency? <p>For example, a step in smaller phase depends on a step in larger phase, this is very tricky. TasCreed only validates the cyclic dependency of the step dependencies, not the phase orders. In case of any unexpected blocking issue, users need to make sure the phase order doesn't introduce cyclic dependency.</p>"},{"location":"detail/definition/Phase.html#states-of-dependent-steps","title":"States of dependent steps","text":"<p>When the tasks of a step is created, the state of the dependent steps are passed to them.</p> <ul> <li><code>dependentStepStates</code>: the state of dependent steps</li> <li><code>prevPhaseStepStates</code>: the state of steps in previous phase</li> </ul> <p>With the states of dependent steps, a task executor can implement the conditional branch logic according to the dependent steps are success or failed, it brings more flexibility.</p>"},{"location":"detail/definition/Routine.html","title":"Routine","text":"<p>Routine introduces a new kind of executor, working as a long run job across the whole cluster, round and round again.</p> <p>When TasCreed cluster starts up, the routines will be occupied and executed automatically.</p> <p>Some system routines are defined to work as</p> <ul> <li>monitor: collect and export whole cluster status</li> <li>job watcher: update job status and create new tasks</li> <li>schedule watcher: check schedule trigger condition and trigger jobs</li> </ul>"},{"location":"detail/definition/Routine.html#define-a-routine","title":"Define a routine","text":"<p>Routine executor can be implemented based on two types of parent classes</p> <ul> <li><code>NormalRoutineExecutor</code></li> <li><code>CheckpointRoutineExecutor</code>, can persist checkpoint in bulletin, for failure recovery</li> </ul> <p>Normal routine executor is usually enough.</p> <p>A sample routine executor is defined as below:</p> <pre><code>@RoutineExec(routine=\"simple\", scale = 2, interval = 15 * 1000L)\n@Component\n@Scope(\"prototype\")\npublic class SimpleRoutineExecutor extends NormalRoutineExecutor {\n\n    int i = 0;\n\n    @Override\n    protected void initImpl() throws TcException {\n        System.out.println(String.format(\"routine [%s] init\", routine.getFullName()));\n    }\n\n    @Override\n    protected void executeRoundImpl() throws TcException {\n        try {\n            System.out.println(\"===== routine executor run round begins =====\");\n            i++;\n\n            System.out.println(String.format(\"routine [%s] running %d\", routine.getFullName(), i));\n\n            System.out.println(\"===== routine executor run round ends =====\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    protected void closeImpl() throws TcException {\n        System.out.println(String.format(\"routine [%s] close\", routine.getFullName()));\n    }\n\n}\n</code></pre> <p>The routine executor needs to implement the methods:</p> <ul> <li><code>initImpl</code>: invoked when executor starts</li> <li><code>executeRoundImpl</code>: invoked in a while loop, with a configured interval</li> <li><code>closeImpl</code>: invoked when executor ends</li> </ul> <p>The annotation part is introduced in the document of annotation.</p>"},{"location":"detail/definition/Routine.html#configure-the-routine-resources","title":"Configure the routine resources","text":""},{"location":"detail/definition/Routine.html#configure-routine-threads","title":"Configure routine threads","text":"<pre><code>tascreed:\n  routine:\n    # num of overall available routines\n    max.count.overall:\n      key: \"%s/max_routine_count_overall\"\n      default: 20\n    # num of available routine thread per host\n    max.count.per.host:\n      key: \"%s/max_routine_count_per_host\"\n      default: 5\n</code></pre> <p>This is the default configuration of routine threads</p> <ul> <li>whole cluster can run at most <code>20</code> routine threads, which can be overwritten by the properties file or config bulletin</li> <li>each TasCreed node can run at most <code>5</code> routine threads, which can be overwritten by the properties file or config bulletin</li> </ul>"},{"location":"detail/definition/Routine.html#configure-routine-parameters","title":"Configure routine parameters","text":"<p>The routine parameters are initially configured in the code, they can also be overwritten by properties file.</p> <pre><code># tascreed routine param\ntascreed.routine.param.job-watcher.scale=1\ntascreed.routine.param.job-watcher.interval=10000\ntascreed.routine.param.monitor.interval=5000\ntascreed.routine.param.monitor.priority=101\n</code></pre> <p>The format of the parameter configuration is like <code>tascreed.routine.param.&lt;routineName&gt;.&lt;paramName&gt;</code>.</p>"},{"location":"detail/definition/Routine.html#ban-routines","title":"Ban routines","text":"<p>To enable or disable the routines, you can refer to the document of ban feature.</p>"},{"location":"detail/definition/Schedule.html","title":"Schedule","text":"<p>Jobs are triggered by job requests from users or other systems. What if we want to trigger a job at a specific time, or periodically?</p> <p>Scheduling is such a feature to trigger jobs as predefined time points or periods, automatically.</p>"},{"location":"detail/definition/Schedule.html#workflow","title":"Workflow","text":"<pre><code>flowchart LR\n    SD[\"Schedule Define\"] --&gt;|generate when&lt;br&gt; condition meets| TR[\"Trigger\"]\n    TR --&gt;|submit| JR[\"Job Request\"]\n    JR --&gt;|build| JB[\"Job\"]</code></pre> <p>When schedule triggers, a job request is generated and submitted to the job system.</p>"},{"location":"detail/definition/Schedule.html#example","title":"Example","text":"<p>Let's define a schedule like this:</p> <pre><code>{\n  \"scheduleName\": \"schedule-test\",\n  \"jobRequest\": {\n    \"jobName\": \"sample\",\n    \"trigger\": \"test\",\n    \"params\": {\n      \"p1\": \"${var1}\",\n      \"p3\": \"date-${var3}\"\n    },\n    \"steps\": [\n      {\n        \"name\": \"prep\",\n        \"ignore\": false,\n        \"params\": {\n          \"p2\": \"${var2}\"\n        }\n      }, {\n        \"name\": \"calc\",\n        \"ignore\": false,\n        \"params\": {\n          \"p2\": \"${var2}\"\n        }\n      }, {\n        \"name\": \"aggr-1\",\n        \"traits\": {\n          \"disable\": [\"ARCHIVE\"]\n        }\n      }\n    ]\n  },\n  \"conf\": {\n    \"type\": \"period\",\n    \"intervalMs\": 600000\n  },\n  \"variables\": {\n    \"var1\": {\n      \"type\": \"const\",\n      \"value\": \"str1\"\n    },\n    \"var2\": {\n      \"type\": \"count\",\n      \"next\": 2\n    },\n    \"var3\": {\n      \"type\": \"time\",\n      \"pattern\": \"yyyyMMdd\",\n      \"zone\": \"UTC\"\n    }\n  }\n}\n</code></pre>"},{"location":"detail/definition/Schedule.html#job-request","title":"Job request","text":"<p>The <code>jobRequest</code> field defines the job request template, which is used to generate a job request each time triggered.</p> <p>Distinguish triggers</p> <p>To distinguish triggers, the job requests can differ in some fields, by replacing some fields with the trigger time.</p> <ul> <li><code>trigger</code> field in job request will be suffixed by the trigger time (UTC) in format of <code>-yyyyMMddHHmmss</code> (1)</li> <li>the <code>${xxx}</code> format string in the param values can be replaced by variables, both job params and step params (2)</li> </ul> <ol> <li>For example, the schedule is triggered at <code>2023-02-10T11:00:00.000Z</code>, the <code>trigger</code> field of the job request is <code>test-20230210110000</code></li> <li>For example, <code>${var2}</code> can be replaced by the value of <code>var2</code>, like <code>5</code>, <code>${var3}</code> can be replaced by trigger time in format of <code>20230210</code></li> </ol>"},{"location":"detail/definition/Schedule.html#schedule-config","title":"Schedule config","text":"<p>The <code>conf</code> field defines the schedule config, indicating the time-based schedule information.</p> <ul> <li><code>point</code>: list of time points to trigger</li> <li><code>period</code>: periodically trigger, within an optional time range</li> <li><code>cron</code>: cron expression described trigger time, within an optional time range</li> </ul> <p>Examples</p> <pre><code>// point type, trigger at 3 time points\n{\n  \"type\": \"point\",\n  \"points\": [\"2023-02-10T11:00:00.000Z\", \"2023-02-11T11:00:00.000Z\", \"2023-02-12T11:00:00.000Z\"]\n}\n\n// period type, from a start date, every 10 minutes\n{\n  \"type\": \"period\",\n  \"intervalMs\": 600000,\n  \"startDate\": \"2023-02-10T11:00:00.000Z\"\n}\n\n// cron type, from a start date, every 10 minutes\n{\n  \"type\": \"cron\",\n  \"cron\": \"0 0/10 * * * ?\",\n  \"startDate\": \"2023-02-10T11:00:00.000Z\"\n}\n</code></pre>"},{"location":"detail/definition/Schedule.html#variable","title":"Variable","text":"<p>The <code>variables</code> field defines the variables calculated for each trigger, used to replace param values in job request.</p> <ul> <li><code>const</code>: constant string for direct replacement</li> <li><code>count</code>: counter number, increase after replacement</li> <li><code>time</code>: time string of trigger time for replacement</li> </ul> <p>Examples</p> <pre><code>// const type, value is constant\n{\n  \"type\": \"const\",\n  \"value\": \"my-string\"\n}\n\n// count type, start from 2\n{\n  \"type\": \"count\",\n  \"next\": 2\n}\n\n// time type, trigger time in string format\n{\n  \"type\": \"time\",\n  \"pattern\": \"yyyyMMdd\",\n  \"zone\": \"UTC\"\n}\n</code></pre>"},{"location":"detail/definition/Trait.html","title":"Trait","text":"<p>Traits describe the properties of TasCreed data objects, such as jobs, steps, etc. An object can have arbitrary number of traits.</p>"},{"location":"detail/definition/Trait.html#trait-type","title":"Trait Type","text":"<p>Each trait is categorized to a type, which can be configured on several kinds of data objects.</p> Trait type Valid data objects <code>JOB_DEFINE</code> <code>JOB_DEFINE</code> <code>STEP_DEFINE</code> <code>STEP_DEFINE</code> <code>JOB</code> <code>JOB</code>, <code>JOB_DEFINE</code> <code>STEP</code> <code>STEP</code>, <code>STEP_DEFINE</code> <code>TASK</code> <code>TASK</code>, <code>STEP</code>, <code>STEP_DEFINE</code> <p>For example, <code>CAN_FAIL</code> trait is <code>STEP</code> type, it can be used to a step define or step.  </p> <p>In step define, it can be configured like this: <pre><code>{\n  \"stepName\": \"calc-2\",\n  \"dependency\": {\n    \"steps\": [\"prep\"]\n  },\n  \"traits\": [\"canFail\"]\n}\n</code></pre></p> <p>When the step is created, <code>CAN_FAIL</code> trait is inherited: <pre><code>{\n  \"stepName\": \"calc-2\",\n  \"traits\": [\"canFail\"]\n}\n</code></pre></p> <p>But when the task is created, <code>CAN_FAIL</code> trait will not be seen, because it doesn't impact task: <pre><code>{\n  \"stepName\": \"calc-2\"\n}\n</code></pre></p> Why <code>CAN_FAIL</code> trait is not seen in task? <p>Because the task executor doesn't care if the task can fail or not, only when we want to figure out the step result, the task failure affects.</p>"},{"location":"detail/definition/Trait.html#trait_1","title":"Trait","text":"<p>By now, there are 4 traits defined. The trait can be used by name or aliases, case-sensitive.</p>"},{"location":"detail/definition/Trait.html#can_ignore","title":"CAN_IGNORE","text":"<ul> <li>name: <code>CAN_IGNORE</code></li> <li>aliases: <code>canIgnore</code>, <code>can-ignore</code>, <code>ignorable</code></li> <li>type: <code>STEP_DEFINE</code></li> <li>usage: the step can be ignored; only if this step is explicitly ignored by the job request, the step will be ignored.</li> </ul>"},{"location":"detail/definition/Trait.html#deleted","title":"DELETED","text":"<ul> <li>name: <code>DELETED</code></li> <li>aliases: <code>deleted</code></li> <li>type: <code>JOB</code></li> <li>usage: the job is deleted; this trait can not be configured by user</li> </ul>"},{"location":"detail/definition/Trait.html#can_fail","title":"CAN_FAIL","text":"<ul> <li>name: <code>CAN_FAIL</code></li> <li>aliases: <code>canFail</code>, <code>can-fail</code></li> <li>type: <code>STEP</code></li> <li>usage: the step can be failed; if the step final result is <code>FAILED</code>, it will be set as <code>ACCEPTABLE_FAILED</code>, with the result seen as a <code>SUCCESS</code>.</li> </ul>"},{"location":"detail/definition/Trait.html#archive","title":"ARCHIVE","text":"<ul> <li>name: <code>ARCHIVE</code></li> <li>aliases: <code>archive</code></li> <li>type: <code>TASK</code></li> <li>usage: the task will be archived when it finishes; by default the finished tasks will be simply dropped, but some important tasks, which need to be tracked in the future, can be configured to be archived when finished.</li> </ul>"},{"location":"detail/execution/AdvancedFeatures.html","title":"Advanced Features","text":""},{"location":"detail/execution/AdvancedFeatures.html#specify-step-executor","title":"Specify step executor","text":"<p>The task executor can be registered to a step:</p> <ul> <li>in code (by <code>@TaskExec</code> annotation or explicitly call the <code>registerTaskExecutor</code> method of the <code>TaskExecutorRegistry</code>), </li> <li>or specify in job define,</li> <li>or overwrite in job request.</li> </ul> <p>The overwrite level is from low to high.</p> <p>This feature can be used to overwrite the executor for a specific run.</p>"},{"location":"detail/execution/AdvancedFeatures.html#job-define-directories","title":"Job define directories","text":"<p>The job defines are loaded when application starts up, from the configured directories in <code>tascreed.define.dirs</code>, the directories can be separated by <code>,</code>.</p> <p>These directory paths are prefixed by <code>classpath:/</code>, all the files with <code>.json</code> suffix in the directories will be loaded. Therefore, the job define directories can locate in the places that springboot can load resources from.</p>"},{"location":"detail/execution/AdvancedFeatures.html#priority","title":"Priority","text":"<p>Users can specify the priority of a job define, or overwrite it in job request, the tasks of higher prioritized jobs will be picked up first.</p> <p>The priority is an integer, the larger number the higher priority.</p> <p>Similarly, the routine define can also be prioritized.</p>"},{"location":"detail/execution/AdvancedFeatures.html#ignorable-step","title":"Ignorable Step","text":"<p>In step define, users can specify the step is ignorable or not, by default not.</p> <p>Example of ignorable step define: <pre><code>{\n  \"jobName\": \"job1\",\n  \"steps\": [\n    {\n      \"stepName\": \"step1\",\n      \"traits\": [\"ignorable\"]\n    },\n    ...\n  ]\n}\n</code></pre></p> <p>An ignorable step can be ignored in job request, like this: <pre><code>{\n  \"jobName\": \"job1\",\n  \"steps\": [\n    {\n      \"stepName\": \"step1\",\n      \"ignore\": true\n    }\n  ]\n}\n</code></pre></p> <p>Then the step of this job instance will be set as <code>IGNORED</code> state, with a <code>SUCCESS</code> result.</p>"},{"location":"detail/execution/AdvancedFeatures.html#long-run-pack-mode","title":"Long run pack mode","text":"<p>This step mode is used for the parallel consumption of an endless data stream. For example, <pre><code>{\n  \"jobName\": \"job1\",\n  \"steps\": [\n    {\n      \"stepName\": \"step1\",\n      \"stepType\": \"PACK\",\n      \"packConf\": {\n        \"size\": 100,\n        \"start\": 1000,\n        \"infinite\": true\n      }\n    }\n  ]\n}\n</code></pre></p> <p>The <code>infinite</code> flag indicates a long run pack mode step, the packs will be generated continuously, without an end offset. <pre><code>1000-1099, 1100-1199, 1200-1299, ...\n</code></pre></p> <p>Then each pack task can consume the data stream by the pack range, in parallel.</p>"},{"location":"detail/execution/AdvancedFeatures.html#unique-alive-job","title":"Unique alive job","text":"<p>By default, multiple job instances of a job define can be executed at the same time. But in some scenarios, we need to ensure only one job instance is alive at the same time, then the <code>uniqueAliveInstance</code> flag can be set in job define.</p> <p>For example, <pre><code>{\n  \"jobName\": \"job1\",\n  \"uniqueAliveInstance\": true,\n  ...\n}\n</code></pre></p> <p>Then users can trigger at most one job instance of the job define at the same time.</p>"},{"location":"detail/execution/AdvancedFeatures.html#task-checkpoint","title":"Task checkpoint","text":"<p><code>CheckpointTaskExecutor</code> can persist the checkpoint in bulletin, then the task can continue from the checkpoint if it recovers from failure, such as node restart.</p> <p>To leverage this feature, users need to: </p> <ul> <li>implement <code>TaskExecCheckpoint</code> interface for the checkpoint serialization &amp; deserialization</li> <li>implement <code>CheckpointTaskExecutor</code> for the task executor</li> <li>implement <code>executeRoundImpl</code> method in the task executor, the checkpoint will be updated after each round of execution (1)</li> </ul> <ol> <li>In contrast, users need to implement <code>executeImpl</code> method for <code>NormalTaskExecutor</code></li> </ol>"},{"location":"detail/execution/AdvancedFeatures.html#execution-timeout-metric","title":"Execution timeout metric","text":"<p>Users can set the expected execution time for a job or step, using the <code>duration</code> field (in milliseconds) in the job/step define, or overwrite in the job request.  </p> <pre><code>{\n  \"jobName\": \"job1\",\n  \"duration\": 300000,\n  ...\n}\n</code></pre> <p>If the alive job/task execution time exceeds the duration, the metric can be reported by TasCreed infra, to tell the users there are some slow jobs or tasks.</p>"},{"location":"detail/execution/AdvancedFeatures.html#others","title":"Others","text":""},{"location":"detail/execution/AdvancedFeatures.html#affinity-rule","title":"Affinity rule","text":"<p>Dispatch task executor to worker node with specific affinity rule, it is useful in specific environment, but not generic or configurable enough in the open source version. Need to be enhanced.</p>"},{"location":"detail/execution/BanJobs.html","title":"Ban &amp; Resume","text":"<p>In TasCreed, we provide the ban function to disable/enable the execution of task or routine, this feature is called ban &amp; resume.</p>"},{"location":"detail/execution/BanJobs.html#ban-jobs","title":"Ban jobs","text":"<p>We can ban a job, to disable all the tasks of this job; or we can ban all the jobs, to disable any task execution. The ban function is determined by two dimensions, scope and action.</p> <p>First, users need to decide to ban at which scope:</p> <ul> <li>job: all tasks of the specific job instance will be impacted</li> <li>job define: bigger scope than job, all tasks of the job instances of the specific job define will be impacted</li> <li>global: bigger scope than job define, all tasks are impacted</li> </ul> <p>After determining the scope, we can choose the action level, defined for different scopes:</p> Ban level Global Job define Job <code>TASK_PICK</code> Y Y Y <code>TASK_CREATE</code> Y Y Y <code>JOB_SUBMIT</code> Y Y - <ul> <li><code>TASK_PICK</code>: can not pick task to execute, but can still create new tasks</li> <li><code>TASK_CREATE</code>: cover <code>TASK_PICK</code> level, and can not create new tasks</li> <li><code>JOB_SUBMIT</code>: cover <code>TASK_CREATE</code> level, and can not submit new job instance</li> </ul> <p>If a task has been picked and executing, it can not be stopped.</p>"},{"location":"detail/execution/BanJobs.html#ban-routines","title":"Ban routines","text":"<p>Similarly, we can ban the execution of routines. The ban function is also determined by the two dimensions.</p> <p>First, users need to decide to ban at which scope:</p> <ul> <li>routine: the specific routine instance will be impacted</li> <li>routine define: all instances of a specific routine define will be impacted</li> </ul> <p>After determining the scope, we can choose the action level, defined for different scopes:</p> Ban level Routine define Routine <code>ROUTINE_EXEC</code> Y Y <code>ROUTINE_OCCUPY</code> Y Y <ul> <li><code>ROUTINE_EXEC</code>: can not execute routine</li> <li><code>ROUTINE_OCCUPY</code>: cover <code>ROUTINE_EXEC</code> level, and can not occupy routine; if a routine is already occupied, it will be dropped</li> </ul> <p>Routine is executed round and round, thus the current running round can not be stopped, but the next round can.</p>"},{"location":"detail/execution/Progression.html","title":"Progression","text":"<p>TasCreed can calculate the progress of a job or step in percentage format, then users can easier to know where the execution achieves.</p>"},{"location":"detail/execution/Progression.html#job-progression","title":"Job progression","text":"<p>Job progression is determined by steps.</p> <p>Each step has an optional parameter <code>effort</code>, by default is <code>1</code>, as the weight during calculation.</p> <pre><code>Job progression = sum(success step effort) / sum(all step effort) * 100%\n</code></pre>"},{"location":"detail/execution/Progression.html#step-progression","title":"Step progression","text":"<p>Step progression is determined by tasks, but differentiated by step modes.</p> <ul> <li>Simple: success <code>100%</code>, other <code>0%</code></li> <li>Shard: <code>count(success shard) / count(total shard) * 100%</code></li> <li>Pack: <code>count(success pack) / count(total pack) * 100%</code><ul> <li>Infinite Pack: <code>0%</code>, because the step never ends</li> </ul> </li> </ul>"},{"location":"detail/execution/States.html","title":"States","text":"<p>TasCreed tracks the state of a job, step, and task, here introduces the states of each object.</p>"},{"location":"detail/execution/States.html#state-definition","title":"State definition","text":"<p>Each type of state is determined by two kinds of information, the completion and result.</p> <ul> <li>Completion, could be <code>UNDONE</code> or <code>DONE</code>, indicates the object is finished or not.</li> <li>Result, could be <code>UNKNOWN</code>, <code>SUCCESS</code>, <code>FAILED</code>, or <code>ERROR</code>, indicates the object has a certain result or not.</li> </ul> <p>Difference between <code>FAILED</code> and <code>ERROR</code> results</p> <ul> <li><code>FAILED</code> indicates an expected failure of execution, which will only fail the current and following steps, but the other non-dependent steps can keep working.</li> <li><code>ERROR</code> indicates a non-expected exception during execution, which will mark the current step and the whole job as <code>ERROR</code> state, then all the remaining steps of the job will not be executed, except the tasks already created.</li> </ul> <p>Usually, <code>FAILED</code> means retryable, while <code>ERROR</code> means non-retryable.</p>"},{"location":"detail/execution/States.html#task-state","title":"Task state","text":"<pre><code>flowchart LR\n    UNDONE --&gt;|task finish with&lt;br&gt; success result| SUCCESS\n    UNDONE --&gt;|task finish with&lt;br&gt; failed result| FAILED\n    UNDONE --&gt;|task finish by&lt;br&gt; an exception| ERROR</code></pre> State Completion Result Description <code>UNDONE</code> <code>UNDONE</code> <code>UNKNOWN</code> the default state of a new created task <code>SUCCESS</code> <code>DONE</code> <code>SUCCESS</code> the task is successfully finished <code>FAILED</code> <code>DONE</code> <code>FAILED</code> the task is finished with a failed result <code>ERROR</code> <code>DONE</code> <code>ERROR</code> the task is finished by a non-expected exception <p>User changes the task state</p> <p>TasCreed will NOT automatically set the task state when it finishes, users need to explicitly set the task state when implementing the execution method of <code>TaskExecutor</code>.  So users can decide which kind of task state to use.</p>"},{"location":"detail/execution/States.html#step-state","title":"Step state","text":"<pre><code>flowchart LR\n    DORMANT --&gt;|start to create tasks| START\n    DORMANT --&gt;|step ignored by request| IGNORED\n    DORMANT --&gt;|any dependent step&lt;br&gt; has error result| SKIP_BY_ERROR\n    DORMANT --&gt;|any dependent step&lt;br&gt; has failed result,&lt;br&gt; and this step&lt;br&gt; can not fail| SKIP_BY_FAILED\n    DORMANT --&gt;|any dependent step&lt;br&gt; has failed result,&lt;br&gt; and this step&lt;br&gt; can fail| ACCEPTABLE_FAILED\n\n    START --&gt;|all tasks created| READY\n\n    READY --&gt;|any task is failed,&lt;br&gt; and this step&lt;br&gt; can fail| ACCEPTABLE_FAILED\n    READY --&gt;|any task is failed,&lt;br&gt; and this step&lt;br&gt; can not fail| FAILED\n    READY --&gt;|any task is error| ERROR\n    READY --&gt;|all tasks are success| SUCCESS</code></pre> State Completion Result Description <code>DORMANT</code> <code>UNDONE</code> <code>UNKNOWN</code> the default state of a step <code>START</code> <code>UNDONE</code> <code>UNKNOWN</code> the step starts to create tasks, and not finished the task creation <code>READY</code> <code>UNDONE</code> <code>UNKNOWN</code> the tasks of the step are all created <code>SUCCESS</code> <code>DONE</code> <code>SUCCESS</code> all the tasks of this step are success, so the step is success <code>FAILED</code> <code>DONE</code> <code>FAILED</code> some task of this step is failed, and this step can not fail, so the step is failed <code>ACCEPTABLE_FAILED</code> <code>DONE</code> <code>SUCCESS</code> the step can fail, some task of this step is failed, or any dependent step has a <code>FAILED</code> result, so the step is acceptable failed, not successfully finished but with a <code>SUCCESS</code> result <code>ERROR</code> <code>DONE</code> <code>ERROR</code> some task of this step is error, so the step is error <code>IGNORED</code> <code>DONE</code> <code>SUCCESS</code> the step can be ignored, and the job request asks to ignore this step, then it is ignored, with a <code>SUCCESS</code> result <code>SKIP_BY_FAILED</code> <code>DONE</code> <code>FAILED</code> if any dependent step has a <code>FAILED</code> result, and this step can not fail, then the step is skipped with a <code>FAILED</code> result <code>SKIP_BY_ERROR</code> <code>DONE</code> <code>ERROR</code> if any dependent step has a <code>ERROR</code> result, and this step can not fail, then the step is skipped with a <code>ERROR</code> result; <code>ERROR</code> is prior than <code>FAILED</code> <p>Only if all dependent steps are done, the current step state can be updated.</p> <p>Difference between <code>START</code> and <code>READY</code> states</p> <p>The <code>START</code> and <code>READY</code> states are similar, with the only difference of task creation finished or not. Actually the <code>START</code> state step can be changed to <code>FAILED</code>, <code>ACCEPTABLE_FAILED</code>, <code>ERROR</code> like <code>READY</code> state, but only the <code>READY</code> state step can be changed to <code>SUCCESS</code> state.</p> How does completion &amp; result impact the next steps? <ul> <li>Completion<ul> <li><code>UNDONE</code>: this step is not finished, next steps should be waiting</li> <li><code>DONE</code>: this step is finished, next steps can be triggered</li> </ul> </li> <li>Result<ul> <li><code>SUCCESS</code>: next steps can start as expected</li> <li><code>FAILED</code>: next steps can not start</li> <li><code>ERROR</code>: next steps can not start</li> </ul> </li> </ul> What does it mean that a step can fail or not? <p>A step can fail means its failure is acceptable, it should not block the execution of its following steps. Users can decide the step can fail or not by configuring it with <code>CAN_FAIL</code> trait.  </p> <ul> <li>When the step failure condition is met (any task of the step is failed),<ul> <li>if the step can fail, then it changes to <code>ACCEPTABLE_FAILED</code> state, with a <code>SUCCESS</code> result, which means the failure is acceptable;</li> <li>otherwise, it changes to <code>FAILED</code> state, with a <code>FAILED</code> result, which means the step fails, and the following steps will be impacted.</li> </ul> </li> <li>When the dependent step has a <code>FAILED</code> result,<ul> <li>if the step can fail, then it changes to <code>ACCEPTABLE_FAILED</code> state as well;</li> <li>otherwise, it changes to <code>SKIP_BY_FAILED</code> state, with a <code>FAILED</code> result, meaning it is skipped due to the <code>FAILED</code> result of the dependent step.</li> </ul> </li> </ul> <p>The <code>ERROR</code> result doesn't behave the same, there's not a <code>CAN_ERROR</code> trait. An <code>ERROR</code> result will lead to the <code>SKIP_BY_ERROR</code> state of the next steps.</p>"},{"location":"detail/execution/States.html#job-state","title":"Job state","text":"<pre><code>flowchart LR\n    UNDONE --&gt;|all steps with&lt;br&gt; success result| SUCCESS\n    UNDONE --&gt;|any step with&lt;br&gt; failed result| FAILED\n    UNDONE --&gt;|any step with&lt;br&gt; error result| ERROR\n    UNDONE --&gt;|any step can&lt;br&gt; never start| STUCK</code></pre> State Done enum Result enum Description <code>UNDONE</code> <code>UNDONE</code> <code>UNKNOWN</code> the default state of a job <code>SUCCESS</code> <code>UNDONE</code> <code>SUCCESS</code> all the steps of the job have a <code>SUCCESS</code> result <code>FAILED</code> <code>UNDONE</code> <code>FAILED</code> any step of the job has a <code>FAILED</code> result <code>ERROR</code> <code>UNDONE</code> <code>ERROR</code> any step of the job has a <code>ERROR</code> result <code>STUCK</code> <code>UNDONE</code> <code>ERROR</code> the job is stuck if some step can never by started, due to the circular dependency of the step DAG What leads to a <code>STUCK</code> state? <p>If any step can never be triggered, the whole job will be stuck. This is caused by circular dependency, which can be recognized and alert when reading the job define, so there should not be any job fall into the <code>STUCK</code> state, it is just defined to cover all the possibilities.</p> <p>Only <code>SUCCESS</code> jobs will be archived to the permanent storage, the jobs with other states will be left in bulletin, which can be manually retried afterwards.</p>"},{"location":"detail/execution/UpdateParamConfig.html","title":"Update Param and Config","text":""},{"location":"detail/execution/UpdateParamConfig.html#updated-param","title":"Updated Param","text":"<p>As we know, a job has params, which can be used to pass parameters to the task execution. Actually, after execution, a task can also update the job params, to pass to the subsequently created tasks.</p> <p>This feature can also be used to pass a small sized intermediate result to the subsequent tasks.</p> What if the update param has the same key as the job/step param? <p>The update param has the highest overwrite level, so the subsequent created tasks will see the overwritten value.</p> <p>Sample usage, update param in the end of the <code>executeImpl</code> method in task executor: <pre><code>task.addUpdatedParam(key, value);\n</code></pre></p> <p>Only the subsequently created tasks can see the updated param, e.g. tasks of the next steps.</p>"},{"location":"detail/execution/UpdateParamConfig.html#updated-config","title":"Updated Config","text":"<p>Similarly, we can also update the config of subsequent steps, to modify like the pack range or shard number dynamically. For example, we can count the data volume in the first step, and then set the shard number of the next steps according to the total count. </p> <p>Only the subsequently created steps config can be updated, e.g. following steps depending on current one.</p> <p>Sample usage, update step config in the end of the <code>executeImpl</code> method in task executor: <pre><code>task.addUpdatedConfig(stepName, stepConf);\n</code></pre></p>"},{"location":"detail/management/Archive.html","title":"Archive","text":""},{"location":"detail/management/Archive.html#archive-jobs","title":"Archive jobs","text":"<p>When a job is done with a determined result, <code>SUCCESS</code> or <code>FAILED</code>, it can be archived to the archive storage.</p> <p>Archived jobs can be used for:</p> <ul> <li>job query, to find the historical jobs</li> <li>job deduplication, to avoid dual running of the same job</li> </ul>"},{"location":"detail/management/Archive.html#archive-tasks","title":"Archive tasks","text":"<p>By default, a task is simply removed when it is done.</p> <p>But for the tasks with <code>archive</code> trait (1), it can be archived to the archive storage when it is done.</p> <ol> <li><code>archive</code> trait of a task is inherited from its belonged step, which can be defined in the step define, or overwritten in job request</li> </ol>"},{"location":"detail/management/Archive.html#archive-storage-types","title":"Archive storage types","text":"<p>Users can configure to choose different implementations of archive storages.</p> <p>An example of configuration could be like this:</p> <pre><code>tascreed.storage.archive = ETCD, ES\n</code></pre> <p>The value is a list of the archive storage names. By default, it is set as <code>ES</code> only.</p>"},{"location":"detail/management/Archive.html#es-elasticsearch","title":"ES (ElasticSearch)","text":"<p>Archived jobs are saved in index <code>tascreed_job_&lt;namespace&gt;</code>, and archived tasks are saved in index <code>tascreed_task_&lt;namespace&gt;</code>.</p>"},{"location":"detail/management/Archive.html#etcd","title":"ETCD","text":"<p>Archived jobs are saved in keys with prefix <code>&lt;namespace&gt;/archive/job/</code>, and archive tasks is not supported in ETCD.</p> <p>In ETCD archive storage, <code>tascreed.storage.archive.etcd.retention.hours</code> can configure the retention time of the archived jobs, 7 days by default.</p>"},{"location":"detail/management/Archive.html#none","title":"NONE","text":"<p>Literally, no archive.</p>"},{"location":"detail/management/NodeDuty.html","title":"Node Duty","text":"<p>The TasCreed application can be deployed across different data centers, on multiple nodes. Each node can perform differently if: </p> <ul> <li>during rollout of a new release or any unknown deployment issue, there could be several versions of manifests deployed at the same time;</li> <li>nodes in different data centers perform differently due to network locality.</li> </ul> <p>Users might need to control the node responsibilities differently, based on some conditions, such as manifest version, host name, etc.</p> <p>To support such fine-grained management, we've defined the node duties and the control rules, to guide the TasCreed application nodes work or not.</p>"},{"location":"detail/management/NodeDuty.html#node-duty_1","title":"Node duty","text":"<p>The responsibility of a TasCreed node is defined as a set of duties, which can be enabled or disabled separately.</p> <pre><code>flowchart TD\n    subgraph ALL\n        subgraph SERVER\n            JOB_SERVER\n            STATE_SERVER\n            SCHEDULE_SERVER\n        end\n        subgraph EXECUTOR\n            TASK_EXECUTOR\n            ROUTINE_EXECUTOR\n        end\n    end</code></pre> <p>The containment relationship of these duties are already depicted in the diagram. </p> <p>The child duties controls specific functionalities:</p> <ul> <li><code>JOB_SERVER</code>: manages the APIs of job lifecycle; if disabled on a node, it can not serve for job APIs, and can not refresh job state in background</li> <li><code>STATE_SERVER</code>: manages the other APIs; if disabled on a node, it can not serve for the functionalities of ban, delete adoption/task/job, etc.</li> <li><code>SCHEDULE_SERVER</code>: manages the APIs of schedule lifecycle; if disabled on a node, it can not serve for schedule APIs</li> <li><code>TASK_EXECUTOR</code>: manages the execution of tasks; if disabled on a node, it can not occupy/execute any task</li> <li><code>ROUTINE_EXECUTOR</code>: manages the execution of routines; if disabled on a node, it can not occupy/execute any routine</li> </ul> <p>For simplicity, duties can be controlled at a higher level.</p> <ul> <li><code>SERVER</code>: includes <code>JOB_SERVER</code>, <code>STATE_SERVER</code>, <code>SCHEDULE_SERVER</code></li> <li><code>EXECUTOR</code>: includes <code>TASK_EXECUTOR</code> and <code>ROUTINE_EXECUTOR</code></li> <li><code>ALL</code>: includes <code>SERVER</code> and <code>EXECUTOR</code></li> </ul> <p><code>GET</code> APIs still works</p> <p>When a node is disabled for some specific server duties, only the writable APIs are disabled, it can still serve for the <code>GET</code> APIs.</p>"},{"location":"detail/management/NodeDuty.html#node-duty-rule","title":"Node duty rule","text":"<p>A node duty rule defines the conditions to filter out the invalid nodes, as well as the duties to be disabled on them.</p> <p>Example</p> <pre><code>{\n  \"minValidTcVersion\": \"0.3.2-RELEASE\",\n  \"validHostNameRegex\": \"lvs-.*\",\n  \"disableDutiesIfInvalid\": [\"SERVER\", \"TASK_EXECUTOR\"]\n}\n</code></pre> <p>The <code>disableDutiesIfInvalid</code> describes the duties to be disabled on invalid nodes. The other fields intend to find out the invalid node.</p>"},{"location":"detail/management/NodeDuty.html#version-conditions","title":"Version conditions","text":"<ul> <li><code>minValidTcVersion</code>: the minimum valid TasCreed version; a node is invalid if the TasCreed version is smaller than it.</li> <li><code>minValidAppVersion</code>: the minimum valid application version; a node is invalid if the application version is smaller than it.</li> </ul> Why different version conditions? <p>Typically, the TasCreed is integrated as a library in the user's application. Therefore, we provide two version conditions, to check the version of the integrated TasCreed library, or user's application itself.</p> <p>Requirement to get the application version</p> <p>TasCreed infra reads the user application version by <code>org.springframework.boot.info.BuildProperties</code>. Therefore, the pom file of user's application should contain the <code>spring-boot-maven-plugin</code> with the <code>build-info</code> goal. For example, <pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;id&gt;build-info&lt;/id&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;build-info&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre> Otherwise, the application version will be identified as <code>null</code>, if you've configured <code>minValidAppVersion</code> with a non-blank string, all your nodes will be identified as invalid.</p>"},{"location":"detail/management/NodeDuty.html#host-name-conditions","title":"Host name conditions","text":"<ul> <li><code>validHostNameRegex</code>: the valid host name regex; a node is invalid if its host name can not match the regex.</li> <li><code>invalidHostNameRegex</code>: the invalid host name regex; a node is invalid if its host name matches the regex.</li> </ul>"},{"location":"misc/Releases.html","title":"Released Features","text":""},{"location":"misc/Releases.html#010-snapshot","title":"0.1.0-SNAPSHOT","text":"<ol> <li>define job and step by name</li> <li>job step dependency</li> <li>task sharding</li> <li>RESTful trigger job instance</li> <li>job execution archive to es</li> </ol>"},{"location":"misc/Releases.html#020-snapshot","title":"0.2.0-SNAPSHOT","text":"<ol> <li>affinity rule of step</li> <li>job param as global param</li> <li>updated param as global param</li> <li>job last modify time support</li> <li>support job step in pack mode</li> <li>fix bug of simple time format</li> </ol>"},{"location":"misc/Releases.html#021-snapshot","title":"0.2.1-SNAPSHOT","text":"<ol> <li>register step name with job name</li> <li>configurable step execute class</li> <li>read job define files from multi define dirs</li> <li>limited number of tasks can be built for each job at once</li> </ol>"},{"location":"misc/Releases.html#022-snapshot","title":"0.2.2-SNAPSHOT","text":"<ol> <li>upgrade raptor.io to 0.11.2</li> <li>list job, task, task adoption</li> <li>delete job, task, task adoption</li> <li>close threads gracefully</li> </ol>"},{"location":"misc/Releases.html#023-release","title":"0.2.3-RELEASE","text":"<ol> <li>support ban job submit, task create, task pick in different level</li> <li>prioritize task pick by job priority</li> <li>able to ignore ignorable step in trigger job request</li> <li>long run job step in pack mode support</li> <li>delete alive job with optional archive parameter</li> <li>support unique alive instance config in job define</li> <li>success task can update dormant step config</li> </ol>"},{"location":"misc/Releases.html#024-snapshot","title":"0.2.4-SNAPSHOT","text":"<ol> <li>affinity rule can be overwritten by request</li> <li>checkpoint task executor</li> <li>job/step/task progression percentage expose, with step effort config</li> <li>job/task update lock in each entity level</li> <li>refactor ban function, only covered ban level can be banned</li> <li>embed job/state controller into infra</li> </ol>"},{"location":"misc/Releases.html#025-snapshot","title":"0.2.5-SNAPSHOT","text":"<ol> <li>cache etcd config values, refresh after time out, to reduce etcd hit frequency</li> <li>ban job/task in different level by request</li> <li>fix bug of all ignored steps in a job instance stuck there</li> <li>record the modify thread of task; done tasks could be archived to ES, need to enable this feature in configuration and step define</li> <li>job/step request with task create after time; task with task pick after time. With this feature, TasCreed can support delayed task creation and back-off task retry across threads</li> </ol>"},{"location":"misc/Releases.html#026-snapshot","title":"0.2.6-SNAPSHOT","text":"<ol> <li>trait to support ignorable, archive, delete, canFail features</li> <li>multiple dependent steps to support DAG, verify DAG of job define</li> <li>redefine job/step/task states and state transfer logic</li> </ol>"},{"location":"misc/Releases.html#027-release","title":"0.2.7-RELEASE","text":"<ol> <li>unit test of TasCreed domain and infra</li> <li>enrich job and step validation</li> <li>fix watcher thread sleep bug if any exception</li> <li>metrics to expose TasCreed working state</li> <li>task pick priority consider step empty rate as well</li> <li>update alive job to change step pack size</li> <li>auto archive failed job as success job, fail is acceptable result</li> <li>api of manual retry all error tasks of a job</li> <li>upgrade es to ELK 7, upgrade etcd lib to switch cluster in staging</li> </ol>"},{"location":"misc/Releases.html#028-release","title":"0.2.8-RELEASE","text":"<ol> <li>job server trigger state update and task creation in queue, to accelerate the task creation</li> <li>differentiate monitor and normal heartbeat config</li> <li>step state change<ul> <li>rename state start_failed to skip_by_failed</li> <li>add state skip_by_error</li> <li>error state will not fast fail the job</li> <li>error state can be set by infra: non-retry or fatal exception exceeds max error retry times (by default will retry infinitely)</li> </ul> </li> <li>step config max error times</li> <li>dependent step states are passed to next step tasks</li> <li>step phase field in dependency, a step can start only when all prev phase steps finished</li> </ol>"},{"location":"misc/Releases.html#029-release","title":"0.2.9-RELEASE","text":"<ol> <li>make es as an optional archive storage</li> <li>etcd archive storage purges old jobs for retention</li> <li>metric of task retry times</li> <li>task/job execution time exceed metric</li> <li>users can do task occupation check by demand</li> </ol>"},{"location":"misc/Releases.html#030-release","title":"0.3.0-RELEASE","text":"<ol> <li>TasCreed dedicated es cluster</li> <li>update alive job step max task count and max pick times</li> </ol>"},{"location":"misc/Releases.html#031-release","title":"0.3.1-RELEASE","text":"<ol> <li>define done range state of pack/shard step, users can know the detailed progress and generate watermark for pack step</li> <li>worker count per host can be changed on the fly</li> <li>annotation of task executor registry</li> <li>define routine, make it extensible</li> <li>refactor monitor thread as routine</li> <li>refactor job watcher thread as routine</li> <li>routine params configurable</li> </ol>"},{"location":"misc/Releases.html#032-release","title":"0.3.2-RELEASE","text":"<ol> <li>controller of routine adoption</li> <li>TasCreed lib doesn't depend on raptor parent pom file</li> <li>infinite retry when read global config from etcd</li> <li>node duty rules for node validity control</li> </ol>"},{"location":"misc/Releases.html#033-release","title":"0.3.3-RELEASE","text":"<ol> <li>enable min valid app version control feature</li> <li>version comparison use maven ComparableVersion for better compatibility</li> </ol>"},{"location":"misc/Releases.html#034-release","title":"0.3.4-RELEASE","text":"<ol> <li>invalid node regex in node duty rule</li> <li>sample watermark routine</li> <li>change infinite read global config from etcd to 5 times retry, it can throw exception if any error encountered</li> <li>get routine trigger information in executor</li> <li>execution exception counter is exposed in metric</li> </ol>"},{"location":"misc/Releases.html#035-release","title":"0.3.5-RELEASE","text":"<ol> <li>make cal logger optional, default logger can be configured by property</li> <li>abstract es util and etcd util interfaces, default implementation depends on ebay environment</li> <li>build time schedule module</li> <li>node duty of schedule server</li> </ol>"},{"location":"misc/Releases.html#040-release","title":"0.4.0-RELEASE","text":"<ol> <li>refactor EtcdBulletinStorage to distinguish different data types</li> <li>TasCreed api spec</li> <li>refactor TasCreed dependency lib, ebay related dependency can be replaced by external users</li> <li>ebay related configuration wrapped in one file</li> <li>refactor to extract ebay related dependency from infra package</li> </ol>"},{"location":"misc/ReleasesPlanned.html","title":"Planned Features","text":""},{"location":"misc/ReleasesPlanned.html#041-snapshot","title":"0.4.1-SNAPSHOT","text":"<ol> <li>refine schedule, should be guaranteed</li> <li>query history jobs of a schedule</li> <li>abstract shard and pack step by window</li> <li>refine es config key, avoid collision</li> </ol>"},{"location":"misc/ReleasesPlanned.html#backlog","title":"Backlog","text":"<ol> <li>dependency of other jobs [will not do]</li> <li>job storage CRUD API</li> <li>namespace unique constraint</li> <li>multi namespace for one app [will not do]</li> <li>resource management in sharing group, to better assign task to nodes; similar to the flink task slot sharing</li> <li>monitor of TasCreed</li> <li>follow shard/pack step config, when a sub task finishes, the same shard/pack sub task of the following step can start, as pipeline feature</li> <li>metrics of more alive job insight</li> </ol>"},{"location":"misc/ReleasesPlanned.html#ideas","title":"Ideas","text":"<ol> <li>time wheel, prepare for the timer features [done]</li> <li>schedule routine/job by cron expr [done]</li> <li>schedule by resource management</li> <li>exceptions/errors to downgrade node score, to avoid picking up tasks</li> <li>refactor code to remove the hard dependency of raptor infra [done]</li> <li>abstract shard and pack step by window [plan, think it]<ul> <li>with some properties like concurrency, ordered, etc.</li> <li>window can also be recursive</li> <li>simple step can also be abstracted by window, so a property can be recursivable</li> </ul> </li> <li>one worker node can pick multi tasks at one time [plan]</li> <li>Markov chain super step like workflow, Pregel graph computing model [maybe not a proper idea]</li> </ol>"},{"location":"misc/Upgrade.html","title":"Upgrade Tips","text":""},{"location":"misc/Upgrade.html#extra-version-history","title":"Extra version history","text":""},{"location":"misc/Upgrade.html#from-023-release-to-0231-release","title":"from 0.2.3-RELEASE to 0.2.3.1-RELEASE","text":"<ol> <li>upgrade etcd version to 1.2.9-RELEASE (etcd migration)</li> <li>upgrade raptor-io version to 0.12.3-RELEASE (SWU-Q2)</li> <li>0.2.3.2-RELEASE is the same as 0.2.3.1-RELEASE</li> </ol>"},{"location":"misc/Upgrade.html#from-0231-release-to-0231-up-release","title":"from 0.2.3.1-RELEASE to 0.2.3.1-UP-RELEASE","text":"<ol> <li>change sample app name in raptor_app.xml (no impact)</li> </ol>"},{"location":"misc/Upgrade.html#from-0231-up-release-to-0233-release","title":"from 0.2.3.1-UP-RELEASE to 0.2.3.3-RELEASE","text":"<ol> <li>upgrade raptor-io version to 0.13.3-RELEASE (SWU-Q4)</li> <li>upgrade es version to 1.2.11-RELEASE (ELK 7 upgrade and migration)</li> <li>upgrade etcd version to 1.2.11-RELEASE (staging etcd migration to tess)</li> </ol>"},{"location":"misc/Upgrade.html#from-024-release-to-024-up-release","title":"from 0.2.4-RELEASE to 0.2.4-UP-RELEASE","text":"<ol> <li>change sample app name in raptor_app.xml (no impact)</li> <li>upgrade raptor-io version to 0.12.3-RELEASE (SWU-Q2)</li> <li>already included etcd upgrade in normal commit</li> </ol>"},{"location":"misc/Upgrade.html#most-used-versions","title":"Most used versions","text":"<ul> <li>0.2.3.1-RELEASE<ul> <li>fasorchestrator</li> <li>fasrecongen</li> <li>Thunder</li> <li>cashmanager</li> <li>Pangolin</li> <li>reports</li> <li>Skyscraper</li> <li>Sailfish</li> </ul> </li> <li>0.2.3-RELEASE<ul> <li>pangolin-cleaner</li> <li>fasnvbat</li> </ul> </li> </ul>"},{"location":"misc/Upgrade.html#how-to-use-new-versions","title":"How to use new versions","text":"<p>The extra versions are for environment compatibility, not for main features, so there should be no code change required to use the extra versions with the same minor version. For example, 0.2.3.1-RELEASE has the same features as 0.2.3-RELEASE.</p> <p>Let's start from version 0.2.3, and list all the new features that requires code change if the users want to use the new versions of TasCreed.</p>"},{"location":"misc/Upgrade.html#from-023-to-024","title":"from 0.2.3 to 0.2.4","text":"<ol> <li>checkpoint task executor: this feature enables a new task executor type which can temporarily save checkpoint in task in etcd, then the next task executor of the same task can continue to process data from the checkpoint.<ul> <li>code change required: all the task executor extends <code>TaskExecutor</code> need to change the parent class to <code>NormalTaskExecutor</code></li> <li>if user wants to use checkpoint executor, it should extends <code>CheckpointTaskExecutor</code></li> </ul> </li> <li>refactor ban function, only covered ban level can be banned: this feature changes the ban logic and behaviour.<ul> <li>there should be no usage of ban feature, so no change needed</li> </ul> </li> <li>embed job/state controller into infra: internally build the api controllers in infra level, so application can simply support the TasCreed apis.</li> </ol>"},{"location":"misc/Upgrade.html#from-024-to-025","title":"from 0.2.4 to 0.2.5","text":"<ul> <li>no mandatory code change required for compatibility</li> </ul>"},{"location":"misc/Upgrade.html#from-025-to-026","title":"from 0.2.5 to 0.2.6","text":"<ol> <li>trait to support ignorable, archive, delete, canFail features: this feature implements the <code>ignore step</code>, <code>archive task</code>, <code>delete task</code>, <code>step can fail</code> features in trait mode. Actually all these features are not supported in 0.2.3 except the <code>ignore step</code>, but the implementation is backward compatible, so no code change required.</li> <li>multiple dependent steps to support DAG, verify DAG of job define: this feature supports multiple dependent steps instead of only one dependent step. The implementation is backward compatible, so no code change required.</li> <li>redefine job/step/task states and state transfer logic: this feature redefines the job/step/task states and logic, it defines a full state machine, users can refer to this document. The users of previous versions only generate the <code>SUCCESS</code> task state as result, so it is backward compatible. <ul> <li>From this version on, users can generate the other task states like <code>FAILED</code> and <code>ERROR</code>, and the behaviour of these abnormal states are safely defined, users need to carefully read the document before use the states.</li> </ul> </li> </ol>"},{"location":"misc/Upgrade.html#from-026-to-027","title":"from 0.2.6 to 0.2.7","text":"<ol> <li>enrich job and step validation: this feature validates the job and step defines and requests in a more strict way, like the naming convention, etc. For the normal cases, there should be no change, only if the job define doesn't follow the normal way, for example, the job name with strange charactor. If the job define can not be successfully parsed in dev or staging env, users need to change it.</li> </ol>"},{"location":"misc/Upgrade.html#from-027-to-028","title":"from 0.2.7 to 0.2.8","text":"<ol> <li>accelerate job refresh frequency</li> <li>enhancement of steps<ul> <li>enrich step states</li> <li>step max error time can be configured</li> <li>dependent step states can be passed to the following steps</li> <li>DAG can be separated by different phases</li> </ul> </li> </ol>"},{"location":"misc/Upgrade.html#from-028-to-029","title":"from 0.2.8 to 0.2.9","text":"<ol> <li>abstract archive storages, ES is only one of the choice, users can choose other archive storages, or multiple ones.</li> <li>enhance monitor metrics of task retry and execution time exceed.</li> <li>task occupation can be checked by user in code.</li> </ol>"},{"location":"misc/Upgrade.html#from-029-to-030","title":"from 0.2.9 to 0.3.0","text":"<ol> <li>a TasCreed dedicated ES cluster is applied, the TasCreed applications will access to it by default. Also, you can still choose to configure for your specific ES cluster. </li> <li>step max task count and max pick times can be updated even it is still running.</li> </ol> <p>Please be aware that, from this version on, the TasCreed jobs will be archived to the dedicated ES cluster, instead of the previous shared ES cluster; so all the archived historical jobs can not be found in the new ES cluster.</p> <p>You are free to choose the new specific ES cluster or the previous shared one. - If you choose the default new ES, the dependency and esams key access should be applied. (To apply the key <code>/xfasdatadumper/tascreed/es/auth</code> in Fidelius production environment) - If you choose the previous ES, you just need to explicitly configure the endpoint and related parameters of the old ES in your application properties file to overwrite the ES related configuration in TasCreed infra.</p>"},{"location":"misc/Upgrade.html#from-030-to-031","title":"from 0.3.0 to 0.3.1","text":"<ol> <li>routine introduced, for the long run jobs across the whole cluster.</li> <li>done range state of pack/shard step defined, users can get the progress of the step, even generate watermark for the pack step.</li> <li>worker count per host can be updated in etcd on the fly, no need to restart.</li> <li>annotation to simplify the executor register code effort</li> <li>code change required: In the <code>run</code> method of user's <code>Application</code> class, the <code>TcRunner</code> start up way changes, from 1 step to 2 steps.</li> </ol> <p>Sample code <pre><code>    @Override\n    public void run(ApplicationArguments args) {\n        // TasCreed registers all the executors by annotations\n        tcRunner.init();\n\n        // users can manually register or overwrite the executors before TasCreed runner start\n        registerTaskExecutors();\n\n        // TasCreed runner start\n        tcRunner.start();\n    }\n</code></pre></p> <p>In this way, users can overwrite the executors registered by code (happens in <code>init</code> method), which is more flexible.</p>"},{"location":"misc/Upgrade.html#from-031-to-032","title":"from 0.3.1 to 0.3.2","text":"<ol> <li>routine adoption can be checked via state controller</li> <li>infinite retry when read global config from etcd</li> <li>node duty rules for node validity control</li> </ol>"},{"location":"misc/Upgrade.html#from-032-to-033","title":"from 0.3.2 to 0.3.3","text":"<ol> <li>enable min valid app version control feature</li> <li>version comparison use maven ComparableVersion for better compatibility</li> </ol> <p>Details can be found in this document.</p>"},{"location":"misc/Upgrade.html#from-033-to-034","title":"from 0.3.3 to 0.3.4","text":"<ol> <li>invalid node regex in node duty rule</li> <li>sample watermark routine</li> <li>change infinite read global config from etcd to 5 times retry, it can throw exception if any error encountered</li> <li>get routine trigger information in executor</li> <li>biz error or exception alert from infra</li> </ol>"},{"location":"misc/Upgrade.html#from-034-to-035","title":"from 0.3.4 to 0.3.5","text":"<ol> <li>make cal logger optional, default logger can be configured by property</li> <li>abstract es util and etcd util interfaces, default implementation depends on ebay environment</li> <li>build time schedule module</li> <li>node duty of schedule server</li> </ol>"},{"location":"misc/Upgrade.html#from-035-to-040-latest-version","title":"from 0.3.5 to 0.4.0 (latest version)","text":"<ol> <li>refactor etcd util</li> <li>TasCreed api spec</li> <li>refactor TasCreed dependency lib, ebay related dependency can be replaced by external users</li> <li>ebay related configuration wrapped in one file</li> <li>refactor to extract ebay related dependency from infra package</li> </ol> <p>code change required:  eBay users need to change the configuration file name of es and etcd in the application class. For example: <pre><code>public class TasCreedSampleApplication {\n    public static void main(String[] args) {\n        new SpringApplicationBuilder(TasCreedSampleApplication.class)\n                .properties(\"spring.config.name:fasrt-logger,fasrt-commons,etcd,tascreed-ebay,tascreed,application\")\n                .build()\n                .run(args);\n    }\n}\n</code></pre> The configuration files <code>tascreed-es</code>, <code>tascreed-etcd</code> are wrapped into one file <code>tascreed-ebay</code>.</p> <p>pom file change required: eBay users need to add another dependency of eBay related external storage implementation, including es, etcd, cal, etc. For example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.ebay.magellan&lt;/groupId&gt;\n    &lt;artifactId&gt;tascreed-ext-ebay&lt;/artifactId&gt;\n    &lt;version&gt;${tascreed.version}&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p> <p>Also, from this version on, TasCreed sample app can run without real deployment of etcd or es, there is a default in-memory implementation of etcd, and in-memory implementation of es, developers can debug or run the sample app at local. You can refer to environment configuration.</p>"},{"location":"spec/Job.html","title":"Job","text":"<p>Job is created from a job define, triggered by a job request.</p>"},{"location":"spec/Job.html#example","title":"Example","text":"<pre><code>{\n  \"jobName\": \"sample\",\n  \"trigger\": \"20210104-05\",\n  \"priority\": 10,\n  \"params\": {\n    \"k1\": \"v3\"\n  },\n  \"steps\": [\n    {\n      \"stepName\": \"prep\"\n    }, {\n      \"stepName\": \"calc\",\n      \"stepType\": \"SHARD\",\n      \"shardConf\": {\n        \"shard\": 10\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"spec/Job.html#job_1","title":"Job","text":"<p>Job is identified by</p> <ul> <li><code>jobName</code>: unique name of job define</li> <li><code>trigger</code>: trigger ID of job request, unique for the same job define</li> </ul> <p>Other fields are inherited from job define, or updated by job request.</p>"},{"location":"spec/Job.html#step","title":"Step","text":"<p>Step is identified by</p> <ul> <li><code>stepName</code>: unique name of step within the job</li> </ul> <p>Other fields are inherited from step define, or updated by step request.</p> Why there is no dependency information in steps? <p>The dependency information is defined in job define, should not be overwritten in job request. TasCreed reads the dependency information from the job define, so it is optional to record in each job instance.  </p> <p>However, there could be an exception that, if the dependency is changed, the previously unfinished job will use the changed dependency, which is unexpected.  This should be fixed in future versions. </p>"},{"location":"spec/Job.html#task","title":"Task","text":"<p>Example</p> <pre><code>{\n  \"jobName\": \"sample\",\n  \"trigger\": \"20210104-05\",\n  \"stepName\": \"calc\",\n  \"priority\": 10,\n  \"params\": {\n    \"k1\": \"v3\"\n  },\n  \"stepType\": \"SHARD\",\n  \"shardConf\": {\n    \"total\": 10,\n    \"index\": 3\n  },\n  \"dependentStepStates\": {\n    \"prep\": \"SUCCESS\"\n  }\n}\n</code></pre> <p>Task is created from a step, identified by</p> <ul> <li><code>jobName</code></li> <li><code>trigger</code></li> <li><code>stepName</code></li> <li>other fields determined by step modes<ul> <li><code>SIMPLE</code> mode, <code>stepName</code> is enough to identify</li> <li><code>SHARD</code> mode, shard <code>index</code> is used to identify</li> <li><code>PACK</code> mode, pack <code>id</code> is used to identify</li> </ul> </li> </ul> <p>Other fields are inherited from step, or updated by step results.</p>"},{"location":"spec/JobDefine.html","title":"Job Define","text":"<p>Usually we start from a job define, to describe what we want to do.</p>"},{"location":"spec/JobDefine.html#job-define-directories","title":"Job define directories","text":"<p>A job define is stored in a file, which is </p> <ul> <li>placed in folders configured by <code>tascreed.define.dirs</code></li> <li>suffixed with <code>.json</code></li> <li>visited through <code>classpath:/&lt;dir&gt;/&lt;file&gt;.json</code></li> </ul> <p>TasCreed application loads all the job define files when starting up, after parsing and validating, valid job defines are registered into memory.</p> <p>Each job define file describes a job template, to define how it works.</p>"},{"location":"spec/JobDefine.html#example","title":"Example","text":"<pre><code>{\n  \"jobName\": \"sample\",\n  \"version\": 1,\n  \"priority\": 10,\n  \"uniqueAliveInstance\": true,\n  \"params\": {\n    \"k1\": \"v1\",\n    \"k2\": \"v2\"\n  },\n  \"steps\": [\n    {\n      \"stepName\": \"prep\"\n    }, {\n      \"stepName\": \"calc\",\n      \"stepType\": \"SHARD\",\n      \"shardConf\": {\n        \"shard\": 4\n      },\n      \"dependentStep\": \"prep\"\n    }\n  ]\n}\n</code></pre>"},{"location":"spec/JobDefine.html#job-define_1","title":"Job define","text":"<p>Generally, a job can be simply defined by two parts:</p> <ul> <li><code>jobName</code>: unique name of the job define, TasCreed finds a job by it</li> <li><code>steps</code>: list of step defines, to describe the steps and their dependencies</li> </ul> <p>Other optional fields are used to impact the job scheduling and execution:</p> <ul> <li><code>version</code>: version of the job define, not in use now</li> <li><code>priority</code>: priority of the job define, inherited by job instances and tasks; the larger number the higher priority</li> <li><code>uniqueAliveInstance</code>: if true, only one alive job instance can exist at any time</li> <li><code>params</code>: parameters at job level, inherited by all job instances</li> <li><code>traits</code>: traits of the job define, inherited by job instance</li> <li><code>duration</code>: expected execution time of a job, inherited by job instance</li> </ul>"},{"location":"spec/JobDefine.html#step-define","title":"Step define","text":"<p>A step can also be simply defined by some part:</p> <ul> <li><code>stepName</code>: unique name of the step define within the job define, TasCreed finds a step by it</li> <li><code>stepType</code>: indicates the step work mode<ul> <li><code>SIMPLE</code>: default step type, only one task can be created</li> <li><code>SHARD</code>: several tasks can be created in sharding mode</li> <li><code>PACK</code>: several tasks can be created in pack mode</li> </ul> </li> <li><code>dependentStep</code>: dependent step name of the step, meaning the step can start only after the dependent step done; deprecated, use <code>dependency</code> instead</li> <li><code>dependency</code>: describe the dependency information of the step<ul> <li><code>doneSteps</code>: name list of dependent steps, only when all these steps done can this step start</li> <li><code>phase</code>: belonged phase of this step</li> </ul> </li> </ul> <p><code>dependentStep</code> can only define one dependent step, while <code>dependency</code> can define multiple dependent steps.</p> <p>Other optional fields are used to impact the step scheduling and execution:</p> <ul> <li><code>exeClass</code>: task executor class name of the step, to overwrite the registered executor</li> <li><code>affinityRule</code>: affinity rule of the step, to guide task selection of each node</li> <li><code>effort</code>: effort of the step, used for progress percentage calculation of the whole job</li> <li><code>traits</code>: traits of the step, inherited by tasks</li> <li><code>ignorable</code>: if true, the step can be ignored if the step is set <code>ignore</code> in job request; deprecated, use <code>traits</code> instead</li> <li><code>duration</code>: expected execution time of a step</li> <li><code>params</code>: parameters at step level, inherited by all tasks of the step</li> <li><code>maxPickTimes</code>: max times to pick a task of the step, default is <code>-1</code>, meaning no limit</li> </ul>"},{"location":"spec/JobDefine.html#simple-mode-step","title":"Simple mode step","text":"sample of simple mode step<pre><code>{\n  \"stepName\": \"prep\",\n  \"stepType\": \"SIMPLE\",\n  \"dependentStep\": \"first\",\n  \"params\": {\n    \"k1\": \"v11\", \n    \"k2\": \"v22\"\n  }\n}\n</code></pre> <pre><code>block-beta\n  T[\"prep&lt;br&gt;(simple task)\"]</code></pre> <p>If <code>stepType</code> not set, it is <code>SIMPLE</code> mode by default.</p>"},{"location":"spec/JobDefine.html#shard-mode-step","title":"Shard mode step","text":"sample of shard mode step<pre><code>{\n  \"stepName\": \"calc\",\n  \"stepType\": \"SHARD\",\n  \"shardConf\": {\n    \"shard\": 5\n  }\n}\n</code></pre> <pre><code>block-beta\n  columns 2\n  T0[\"calc.shard-0&lt;br&gt;(total: 5, index: 0)\"]\n  T1[\"calc.shard-1&lt;br&gt;(total: 5, index: 1)\"]\n  T2[\"calc.shard-2&lt;br&gt;(total: 5, index: 2)\"]\n  T3[\"calc.shard-3&lt;br&gt;(total: 5, index: 3)\"]\n  T4[\"calc.shard-4&lt;br&gt;(total: 5, index: 4)\"]</code></pre> <p>The shard mode configuration is defined in <code>shardConf</code> field, which is available for <code>SHARD</code> mode step.</p> <ul> <li><code>shard</code>: the total sharding number, larger than <code>0</code>, recommended to be less than <code>100</code></li> <li><code>startShardId</code>: the start shard id of created shard tasks, by default is <code>0</code></li> <li><code>maxTaskCount</code>: the max number of alive tasks of this step at the same time, by default is <code>50</code></li> </ul>"},{"location":"spec/JobDefine.html#pack-mode-step","title":"Pack mode step","text":"sample of pack mode step<pre><code>{\n  \"stepName\": \"calc\",\n  \"stepType\": \"PACK\",\n  \"packConf\": {\n    \"size\": 100,\n    \"start\": 0,\n    \"end\": 925\n  },\n  \"dependentStep\": \"prep\"\n}\n</code></pre> <pre><code>block-beta\n  columns 2\n  T0[\"calc.pack-0&lt;br&gt;(id: 0, start: 0, end: 99)\"]\n  T1[\"calc.pack-1&lt;br&gt;(id: 1, start: 100, end: 199)\"]\n  T2[\"calc.pack-2&lt;br&gt;(id: 2, start: 200, end: 299)\"]\n  T3[\"calc.pack-3&lt;br&gt;(id: 3, start: 300, end: 399)\"]\n  T4[\"calc.pack-4&lt;br&gt;(id: 4, start: 400, end: 499)\"]\n  T5[\"calc.pack-5&lt;br&gt;(id: 5, start: 500, end: 599)\"]\n  T6[\"calc.pack-6&lt;br&gt;(id: 6, start: 600, end: 699)\"]\n  T7[\"calc.pack-7&lt;br&gt;(id: 7, start: 700, end: 799)\"]\n  T8[\"calc.pack-8&lt;br&gt;(id: 8, start: 800, end: 899)\"]\n  T9[\"calc.pack-9&lt;br&gt;(id: 9, start: 900, end: 925)\"]</code></pre> <p>The pack mode configuration is defined in <code>packConf</code> field, which is available for <code>PACK</code> mode step.</p> <ul> <li><code>size</code>: the size of each pack, larger than <code>0</code></li> <li><code>start</code>: the start point of the whole range, included, should not be negative</li> <li><code>end</code>: the end point of the whole range, included, not needed if the step is infinite</li> <li><code>infinite</code>: if true, the whole range has no end point, the step will create pack tasks infinitely</li> <li><code>startPackId</code>: the start pack id of created pack tasks, by default is <code>0</code></li> <li><code>maxTaskCount</code>: the max number of alive tasks of this step at the same time, by default is <code>50</code></li> </ul> <p>As a special usage, an infinite pack mode step can create tasks infinitely. A sample usage is to consume an endless data stream.</p> sample of infinite pack mode step<pre><code>{\n  \"stepName\": \"consume\",\n  \"stepType\": \"PACK\",\n  \"packConf\": {\n    \"size\": 100,\n    \"start\": 0,\n    \"infinite\": true\n  },\n  \"dependentStep\": \"prep\"\n}\n</code></pre> <pre><code>block-beta\n  columns 2\n  T0[\"consume.pack-0&lt;br&gt;(id: 0, start: 0, end: 99)\"]\n  T1[\"consume.pack-1&lt;br&gt;(id: 1, start: 100, end: 199)\"]\n  T2[\"consume.pack-2&lt;br&gt;(id: 2, start: 200, end: 299)\"]\n  T3[\"consume.pack-3&lt;br&gt;(id: 3, start: 300, end: 399)\"]\n  T4[\"consume.pack-4&lt;br&gt;(id: 4, start: 400, end: 499)\"]\n  T5[\"consume.pack-5&lt;br&gt;(id: 5, start: 500, end: 599)\"]\n  ...</code></pre>"},{"location":"spec/JobRequest.html","title":"Job Request","text":"<p>When job define is ready, users can trigger a job instance by job request. </p>"},{"location":"spec/JobRequest.html#example","title":"Example","text":"<pre><code>{\n  \"jobName\": \"sample\",\n  \"trigger\": \"20210104-05\",\n  \"priority\": 10,\n  \"params\": {\n    \"k1\": \"v3\"\n  },\n  \"steps\": [\n    {\n      \"stepName\": \"prep\",\n      \"ignore\": true\n    }, {\n      \"stepName\": \"calc\",\n      \"shardConf\": {\n        \"shard\": 10\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"spec/JobRequest.html#job-request_1","title":"Job request","text":"<p>Generally, a job request can simply contain two parts:</p> <ul> <li><code>jobName</code>: unique name of the job define, TasCreed finds a job by it</li> <li><code>trigger</code>: ID of this trigger, should be unique for the same job define</li> </ul> <p>The pair of <code>jobName</code> and <code>trigger</code> in a <code>Job</code> should be globally unique.</p> <p>Other optional fields are used to overwrite the job define for this specific job:</p> <ul> <li><code>priority</code>: overwrite the priority for this job</li> <li><code>params</code>: update or provide more params for this job</li> <li><code>steps</code>: overwrite the step defines for this job</li> <li><code>traits</code>: modify the traits for this job</li> <li><code>after</code>: specify the time to start task creation of this job</li> <li><code>duration</code>: overwrite the expected execution time of this job</li> </ul>"},{"location":"spec/JobRequest.html#trait","title":"Trait","text":"sample of modify traits<pre><code>{\n  \"traits\": {\n    \"enable\": [\"CAN_IGNORE\"],\n    \"disable\": [\"CAN_FAIL\"]\n  }\n}\n</code></pre> <p>Modify traits</p> <ul> <li><code>enable</code>: enable some traits for this job</li> <li><code>disable</code>: disable some traits for this job</li> </ul>"},{"location":"spec/JobRequest.html#after","title":"After","text":"sample of job start time<pre><code>{\n  \"after\": {\n    \"timeString\": \"2024-10-28 10:00:00\",\n    \"timePattern\": \"yyyy-MM-dd HH:mm:ss\",\n    \"timeZone\": \"UTC\"\n  }\n}\n</code></pre> <p>Specify start time</p> <ul> <li><code>timeString</code>: time in string format</li> <li><code>timePattern</code>: pattern of the time string, by default is <code>yyyy-MM-dd'T'HH:mm:ss.SSS'Z'</code></li> <li><code>timeZone</code>: time zone, by default is <code>UTC</code></li> <li><code>timestamp</code>: timestamp in numeric format; if this field is set, skip the other fields</li> </ul>"},{"location":"spec/JobRequest.html#step-request","title":"Step request","text":"<p>It is usually unnecessary to provide <code>StepRequest</code> in <code>JobRequest</code>, unless you want to overwrite some steps for this job.</p> <ul> <li><code>stepName</code>: used to identify the step to overwrite</li> <li><code>exeClass</code>: overwrite the task executor class full name for this step</li> <li><code>affinityRule</code>: overwrite the affinity rule name for this step</li> <li><code>ignore</code>: if true, and the step define is <code>ignorable</code>, then this step will be ignored in this job</li> <li><code>traits</code>: modify the traits for this step</li> <li><code>params</code>: update or provide more params for this step</li> <li><code>after</code>: specify the time to start task creation of this step</li> <li><code>duration</code>: overwrite the expected execution time of this step</li> <li><code>maxPickTimes</code>: overwrite max times to pick a task of the step</li> <li><code>shardConf</code>: available for <code>SHARD</code> mode step, overwrite the shard config for this step</li> <li><code>packConf</code>: available for <code>PACK</code> mode step, overwrite the pack config for this step</li> </ul>"},{"location":"spec/Params.html","title":"Param","text":"<p>In TasCreed, params can be passed to task executors at runtime.</p>"},{"location":"spec/Params.html#data-type","title":"Data Type","text":"<p>Params are configured as a map of key-value pairs, in string format. For example:</p> <pre><code>\"params\": {\n  \"k1\": \"v1\",\n  \"k2\": \"v2\"\n}\n</code></pre>"},{"location":"spec/Params.html#overwrite-rule","title":"Overwrite rule","text":"<p>Params can be</p> <ul> <li>configured in <code>JobDefine</code>, <code>StepDefine</code></li> <li>updated or complemented in <code>JobRequest</code></li> <li>inherited in <code>Job</code>, <code>Step</code>, <code>Task</code></li> </ul> <p>Only the params in <code>Task</code> are actually used at runtime.</p>"},{"location":"spec/Params.html#job-param","title":"Job param","text":"<pre><code>Job params = JobDefine params + JobRequest params\n</code></pre> <p><code>Job</code> params are union of <code>JobDefine</code> params and <code>JobRequest</code> params, the latter overwrites the former.</p>"},{"location":"spec/Params.html#step-param","title":"Step param","text":"<pre><code>Step params = StepDefine params + StepRequest params\n</code></pre> <p><code>Step</code> params are union of <code>StepDefine</code> params and <code>StepRequest</code> params, the latter overwrites the former. </p> <p><code>StepRequest</code> is the step part in <code>JobRequest</code>.</p>"},{"location":"spec/Params.html#task-param-generation","title":"Task Param Generation","text":"<pre><code>Task params = Job params + Step params + Job updated params\n</code></pre> <p><code>Task</code> params are union of <code>Job</code> params, <code>Step</code> params and <code>Job</code> updated params, the latter overwrites the former.</p>"}]}